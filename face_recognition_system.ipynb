{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K45oxPuOfAzn"
      },
      "outputs": [],
      "source": [
        "#1. Generation dataset\n",
        "#2. Training classifier and save it\n",
        "#3. Detect the face and named it if it is already stored in our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcQCklrwifzw",
        "outputId": "8bb9ead6-bd29-4af1-f954-392405fcdb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'face-time-attendance-system'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), 140.79 KiB | 1.44 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DucMinhNgo/face-time-attendance-system.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLjFiv4ai3lp",
        "outputId": "f755264d-cd92-478a-b225-35904eba8702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/face-time-attendance-system\n"
          ]
        }
      ],
      "source": [
        "%cd /content/face-time-attendance-system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g67Xzat6ffip",
        "outputId": "e9781b35-4f07-4d29-e83d-af6ab9d9e16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /Users/dustin/miniconda3/lib/python3.10/site-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /Users/dustin/miniconda3/lib/python3.10/site-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "# Generation\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uLUiJ-HNftb9"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "dyLN8vdDf0iN",
        "outputId": "a50f0226-188a-43a6-eadc-261bd74b22d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "/var/folders/r5/5v_j803101v_nmxqj00wtl100000gn/T/ipykernel_38899/3356530203.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if faces is ():\n",
            "/var/folders/r5/5v_j803101v_nmxqj00wtl100000gn/T/ipykernel_38899/3356530203.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if faces is ():\n",
            "/var/folders/r5/5v_j803101v_nmxqj00wtl100000gn/T/ipykernel_38899/3356530203.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if faces is ():\n",
            "/var/folders/r5/5v_j803101v_nmxqj00wtl100000gn/T/ipykernel_38899/3356530203.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if faces is ():\n",
            "/var/folders/r5/5v_j803101v_nmxqj00wtl100000gn/T/ipykernel_38899/3356530203.py:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if faces is ():\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m   cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollecting samples is completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 23\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m   ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 23\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mface_cropped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     img_id\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m     face \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(face_cropped(frame), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m))\n",
            "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mgenerate_dataset.<locals>.face_cropped\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mface_cropped\u001b[39m(img):\n\u001b[1;32m      4\u001b[0m   gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m----> 5\u001b[0m   faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;66;03m# Scaling factor= 1.3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# Minimum neighbor = 5\u001b[39;00m\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m faces \u001b[38;5;129;01mis\u001b[39;00m ():\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def generate_dataset():\n",
        "  face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
        "  def face_cropped(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
        "    # Scaling factor= 1.3\n",
        "    # Minimum neighbor = 5\n",
        "\n",
        "    if faces is ():\n",
        "      return None\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cropped_face = img[y:y+h, x:x+w]\n",
        "\n",
        "    return cropped_face\n",
        "\n",
        "  cap = cv2.VideoCapture(0)\n",
        "  id=1\n",
        "  img_id=0\n",
        "\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if face_cropped(frame) is not None:\n",
        "      img_id+=1\n",
        "      face = cv2.resize(face_cropped(frame), (200, 200))\n",
        "      face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "      file_name_path = \"data/user.\" + str(id) + \".\" + str(img_id) + \".jpg\"\n",
        "      cv2.imwrite(file_name_path, face)\n",
        "      cv2.putText(face, str(img_id), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
        "      # (50, 50) is the origin point from where text is to be written\n",
        "      # font scale= 1\n",
        "      # thickness = 2\n",
        "      cv2.imshow(\"Cropped face\", face)\n",
        "      if cv2.waitKey(1) == 13 or int(img_id) == 200:\n",
        "        break\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  print(\"Collecting samples is completed\")\n",
        "generate_dataset()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
